# Defaults for eval.py.
#
#
# You must also include a binding for MODEL.
#
# Required to be set:
#
# - MIXTURE_OR_TASK_NAME: The SeqIO Task/Mixture to evaluate on
# - EVAL_OUTPUT_DIR: The dir to write results to.
# - REMOTE_ADDRESSES: A list of PredictionService server addresses.
#
#
# Commonly overridden options:
#
# - DatasetConfig.split
# - DatasetConfig.batch_size
# - DatasetConfig.use_cached
from __gin__ import dynamic_registration

import __main__ as eval_script
import seqio
from t5x import model_inference
from t5x import utils


# Must be overridden
MIXTURE_OR_TASK_NAME = %gin.REQUIRED
EVAL_OUTPUT_DIR = %gin.REQUIRED
REMOTE_ADDRESSES = %gin.REQUIRED

TASK_FEATURE_LENGTHS = {"inputs": None, "targets": None}  # No capping on maximum feature lengths.
# DEPRECATED: Import the this module in your gin file.
MIXTURE_OR_TASK_MODULE = None

eval_script.evaluate:
  dataset_cfg = @utils.DatasetConfig()
  output_dir = %EVAL_OUTPUT_DIR
  inference_evaluator_cls = @seqio.Evaluator
  model_inference_cls = @model_inference.PredictionServiceModelInference
  remote_addresses = %REMOTE_ADDRESSES

seqio.Evaluator:
  logger_cls = [@seqio.PyLoggingLogger, @seqio.TensorBoardLogger, @seqio.JSONLogger]
  num_examples = None  # Use all examples in the dataset.
  use_memory_cache = True

utils.DatasetConfig:
  mixture_or_task_name = %MIXTURE_OR_TASK_NAME
  task_feature_lengths = %TASK_FEATURE_LENGTHS
  split = 'test'
  batch_size = 32
  shuffle = False
  seed = 42
  use_cached = False
  pack = False
  use_custom_packing_ops = False
  module = %MIXTURE_OR_TASK_MODULE
