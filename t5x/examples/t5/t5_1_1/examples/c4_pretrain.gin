from __gin__ import dynamic_registration

import __main__ as train_script
from t5x import models
from t5x import partitioning
from t5x import trainer
from t5x import utils

include "examples/t5/t5_1_1/base.gin"
include "configs/runs/pretrain.gin"

MIXTURE_OR_TASK_NAME = "c4_v220_span_corruption"
MIXTURE_OR_TASK_MODULE = "t5.data.mixtures"
TASK_FEATURE_LENGTHS = {"inputs": 512, "targets": 114}
TRAIN_STEPS = 10000

train/utils.DatasetConfig:
  batch_size = 256
  use_cached = False
  pack = True
  use_custom_packing_ops = True

train_eval/utils.DatasetConfig:
  batch_size = 256
  use_cached = False
  pack = True
  use_custom_packing_ops = True

train_script.train:
  eval_period = 1000
  eval_steps = 100
  random_seed = None

models.EncoderDecoderModel.loss_fn:
  z_loss = 0.0001
  loss_normalizing_factor = 29184  # 256 * 114

trainer.Trainer.num_microbatches = 2
utils.create_learning_rate_scheduler.warmup_steps = 10000

utils.SaveCheckpointConfig:
  period = 2000  # checkpoint frequency
  keep = 1 # only keep one checkpoint

partitioning.ModelBasedPjitPartitioner.num_partitions = 2
