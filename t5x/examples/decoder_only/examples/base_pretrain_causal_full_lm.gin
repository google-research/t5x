# Trains a base-sized causal decoder-only model with a full LM objective on C4.

from __gin__ import dynamic_registration
# Register necessary SeqIO Tasks/Mixtures.
import t5.data.mixtures
import t5x.models
import __main__ as train_script


# Replace 'base' with a different size model (e.g., 'xxl'), if desired.
include 't5x/examples/decoder_only/base.gin'
include 't5x/configs/runs/pretrain.gin'

TRAIN_STEPS = 100_000
DROPOUT_RATE = 0.0
BATCH_SIZE = 2048

MIXTURE_OR_TASK_NAME = "c4_v220_full_lm"
TASK_FEATURE_LENGTHS = {"targets": 626}

# Disable bidirectional attention since we want a fully causal model.
models.DecoderOnlyModel.inputs_bidirectional_attention = False

train_script.train:
  eval_period = 2000
