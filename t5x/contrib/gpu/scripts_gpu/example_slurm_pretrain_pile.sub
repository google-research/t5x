#!/bin/bash
#SBATCH -A example              # slurm account
#SBATCH -p partition            # slurm partition name
#SBATCH -N 1                    # number of nodes
#SBATCH -t 04:00:00             # wall time
#SBATCH -J "t5x:train"          # slurm job name
#SBATCH --exclusive             # exclusive node access
#SBATCH --mem=0                 # all mem avail
#SBATCH --mail-type=FAIL        # only send email on failure
#SBATCH --overcommit            
#SBATCH --dependency=singleton  # tells slurm to run only one job with the same job name at a time
set -x

# Copyright 2022 The T5X Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# File system and volume glue code
#-------------------------------------------------------------------------------
# << CHANGE ! >>
SLURM_ACCOUNT='example'
USERID='exampleperson'

# << CHANGE ! >>
CONTAINER="" # Add link to your built container

# << CHANGE ! >>
BASE_T5X_DIR="...../t5x_git" # path to your clone of the repo
BASE_TFDS_DATA_DIR=""        # path to tfds data directory
BASE_T5X_WORKSPACE_DIR="${BASE_T5X_DIR}/workspace" # path to where outputs will be dumped

# Default env variables for paths required by t5x training scripts
TFDS_DATA_DIR=/t5x_home/datasets/
T5X_DIR=/t5x_home/
T5X_WORKSPACE_DIR=/t5x_home/workspace

# Add the T5x/JAX specific mounts
MOUNTS="--container-mounts=$BASE_T5X_DIR:/$T5X_DIR,$BASE_TFDS_DATA_DIR:/$TFDS_DATA_DIR,$BASE_T5X_WORKSPACE_DIR:$T5X_WORKSPACE_DIR"

# Add T5x/JAX specific exports
EXPORTS="--export=ALL,TFDS_DATA_DIR=${TFDS_DATA_DIR},T5X_DIR=${T5X_DIR},T5X_WORKSPACE_DIR=${T5X_WORKSPACE_DIR},PYTHONPATH=${T5X_DIR}"
#-------------------------------------------------------------------------------

# Command line arguments needed by the underlying scripts
PREC=${PREC:="bfloat16"}
T5_SIZE=${T5_SIZE:="large"}
BSIZE_PER_GPU=${BSIZE_PER_GPU:=32}
ENC_SL=${ENC_SL:=512}
DEC_SL=${DEC_SL:=128}
TRAIN_STEPS=${TRAIN_STEPS:=500}
NUM_MICROBATCHES=${NUM_MICROBATCHES:=1}
ENABLE_FP8=${ENABLE_FP8:=1} # Uses TransformerEngine FP8
TP_SIZE=${TP_SIZE:=1}
TRANSPOSE_BS=${TRANSPOSE_BS:=1} # An optimization for GPUs
MODEL_DIR=${MODEL_DIR}
FUSE_QKV=${FUSE_QKV:=1} # Used with TransformerEngine
PACK=${PACK:=0} # Not supported with TransformerEngine

export GPUS_PER_NODE=${1:-8}
export BASE_SCRIPT=${2:-"${T5X_DIR}/t5x/contrib/gpu/scripts_gpu/multiprocess_pretrain_pile.sh"}
export WITH_MP=1

NUM_GPUS=$(( GPUS_PER_NODE * SLURM_JOB_NUM_NODES ))

# << CHANGE ! >>
# You can add binding to the command below with the following line (after nvidia-smi). Remove the '&&' on the next bash line.
# && bash <<path_to_bind_script>>/bind.sh --cpu=exclusive --ib=single -- \
read -r -d '' cmd <<EOF
cd ${T5X_BASE_DIR}
TFDS_DATA_DIR=${TFDS_DATA_DIR} MODEL_DIR=${MODEL_DIR} PREC=${PREC} T5_SIZE=${T5_SIZE} BSIZE_PER_GPU=${BSIZE_PER_GPU} ENC_SL=${ENC_SL} DEC_SL=${DEC_SL} TRAIN_STEPS=${TRAIN_STEPS} NUM_MICROBATCHES=${NUM_MICROBATCHES} ENABLE_FP8=${ENABLE_FP8} TP_SIZE=${TP_SIZE} TRANSPOSE_BS=${TRANSPOSE_BS} FUSE_QKV=${FUSE_QKV} PACK=${PACK} bash $BASE_SCRIPT
EOF

# create run specific output directory for ease of analysis
FOLDER="${BASE_T5X_DIR}/outputs/multinode/PRETRAIN-${T5_SIZE}-${PREC}-N${SLURM_JOB_NUM_NODES}-n${NUM_GPUS}-Step${TRAIN_STEPS}-BS${BSIZE_PER_GPU}-MBS${NUM_MICROBATCHES}-SL${ENC_SL}_${DEC_SL}-TP${TP_SIZE}-FP8${ENABLE_FP8}"
mkdir -p ${FOLDER}

# redirect both stdout and stderr in the same file for ease of analysis
OUTFILE="${FOLDER}/output-%j-%t.txt"

echo $cmd
srun --ntasks-per-node=${GPUS_PER_NODE} -o $OUTFILE -e $OUTFILE --container-image="$CONTAINER" $MOUNTS $EXPORTS bash -c "${cmd}"
set +x
